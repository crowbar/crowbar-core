#!/bin/bash
#
# Old pacemaker resources must be deleted in the old setup before they get created from upgraded node

LOGFILE=/var/log/crowbar/node-upgrade.log
UPGRADEDIR=/var/lib/crowbar/upgrade
mkdir -p "`dirname "$LOGFILE"`"
exec >>"$LOGFILE" 2>&1

log()
{
    set +x
    echo "[$(date --iso-8601=ns)] [$$] $@"
    set -x
}

log "Executing $BASH_SOURCE"

set -x

mkdir -p $UPGRADEDIR

if [[ -f $UPGRADEDIR/crowbar-delete-pacemaker-resources-ok ]] ; then
    log "Pacemaker resources already successfully deleted"
    exit 0
fi

rm -f $UPGRADEDIR/crowbar-delete-pacemaker-resources-failed

<% if @use_ha %>

# Before stopping all remaining services, put the openvswitch agents into admin_state_down
# See https://jira.prv.suse.net/browse/SCRD-3751
for agent in $(neutron agent-list | grep openvswitch | awk {'print $2'}); do
    neutron agent-update --admin-state-down $agent
done

log "Stopping pacemaker resources..."

# Services need to be stopped before deletion.
# Otherwise we could have services starting up in unwanted locations while deleting constraints.

for type in clone group ms primitive; do
    for resource in $(crm configure show | awk "\$1 == \"$type\" && ! (\$2 ~ /drbd|stonith|remote-|vip-/) {print \$2}"); do
        log "Stopping resource $resource"
        crm --wait resource stop $resource
    done
done

ret=$?
if [ $ret != 0 ] ; then
    log "Error occured during stopping resources."
    echo $ret > $UPGRADEDIR/crowbar-delete-pacemaker-resources-failed
    exit $ret
fi

log "Deleting pacemaker resources..."

crm_cmd=""
for type in location clone group ms primitive; do
    log "Looking at typ $type of resources..."
    for resource in $(crm configure show | awk "\$1 == \"$type\" && ! (\$2 ~ /drbd|stonith|remote-|vip-/) {print \$2}"); do
        printf -v crm_cmd "${crm_cmd}delete $resource\n"
    done
done

# Delete the resources in single transaction - let pacemaker decide the ordering
crm configure <<EOF
$crm_cmd
EOF

ret=$?
if [ $ret != 0 ] ; then
    log "Error occured during deleting resources"
    echo $ret > $UPGRADEDIR/crowbar-delete-pacemaker-resources-failed
    exit $ret
fi

<% if @use_rabbitmq_cluster %>
log "Resetting rabbitmq cluster..."
# Reset the nodes in rabbitmq cluster to avoid ordering problems when cluster is re-built.
# Re-synchronization of cluster can take a long time and include some restarts which can lead
# to temporary service unavailability and confusing error messages in logs.
# We could use rabbitmqctl force_reset here but it is less reliable in this case as it requires
# rabbitmq to be (partially) running which can be hard to ensure.
for node in <%= @rabbitmq_nodes.join(" ") %>; do
    ssh $node rm -rf <%= @mnesia_dir %>
done
<% end %>



<% else %>

log "No HA setup found..."

<% end %>

touch $UPGRADEDIR/crowbar-delete-pacemaker-resources-ok
log "$BASH_SOURCE is finished."
